{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"BIRDCLEF-2022-EDA+MODEL.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# # This Python 3 environment comes with many helpful analytics libraries installed\n","# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# # For example, here's several helpful packages to load\n","\n","# import numpy as np # linear algebra\n","# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# # Input data files are available in the read-only \"../input/\" directory\n","# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","# import soundfile as sf\n","# import os\n","# import librosa\n","# import librosa.display\n","# import matplotlib.pyplot as plt\n","# # for dirname, _, filenames in os.walk('/kaggle/input'):\n","# #     for filename in filenames:\n","# #         print(os.path.join(dirname, filename))\n","\n","# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-10T10:36:23.370510Z","iopub.execute_input":"2022-04-10T10:36:23.371375Z","iopub.status.idle":"2022-04-10T10:36:25.648400Z","shell.execute_reply.started":"2022-04-10T10:36:23.371333Z","shell.execute_reply":"2022-04-10T10:36:25.647450Z"},"trusted":true,"id":"cI65nzBuVkKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# val = sf.read('../input/birdclef-2022/train_audio/afrsil1/XC125458.ogg')\n","# print(val)"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:48:47.273159Z","iopub.execute_input":"2022-04-08T13:48:47.273644Z","iopub.status.idle":"2022-04-08T13:48:47.290232Z","shell.execute_reply.started":"2022-04-08T13:48:47.27361Z","shell.execute_reply":"2022-04-08T13:48:47.289503Z"},"trusted":true,"id":"2vrN--1GVkKy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf = pd.DataFrame(columns=['filepath','target'])"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:48:47.291661Z","iopub.execute_input":"2022-04-08T13:48:47.291967Z","iopub.status.idle":"2022-04-08T13:48:47.306171Z","shell.execute_reply.started":"2022-04-08T13:48:47.291933Z","shell.execute_reply":"2022-04-08T13:48:47.305538Z"},"trusted":true,"id":"leqqJNykVkK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:48:47.307111Z","iopub.execute_input":"2022-04-08T13:48:47.308024Z","iopub.status.idle":"2022-04-08T13:48:47.321162Z","shell.execute_reply.started":"2022-04-08T13:48:47.307974Z","shell.execute_reply":"2022-04-08T13:48:47.320723Z"},"trusted":true,"id":"mGS9WdKaVkK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAIN_BASE_URL = '../input/birdclef-2022/train_audio' "],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:48:47.322137Z","iopub.execute_input":"2022-04-08T13:48:47.322469Z","iopub.status.idle":"2022-04-08T13:48:47.335547Z","shell.execute_reply.started":"2022-04-08T13:48:47.322445Z","shell.execute_reply":"2022-04-08T13:48:47.334733Z"},"trusted":true,"id":"2f3OC42AVkK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# l=[]\n","# count=0\n","# j=0\n","# for root, dirs, files in os.walk(TRAIN_BASE_URL):\n","#     for d in dirs:\n","#         WHERE = os.path.join(TRAIN_BASE_URL,d)\n","#         for subr, subd, subf in os.walk(WHERE):\n","#             for f in subf:\n","#                 if count > 100: \n","#                     count=0\n","#                     break\n","#                 filepath = os.path.join(WHERE, f) # path to an ogg file\n","# #                 val, sample_rate=sf.read(filepath)\n","#                 datadf=datadf.append({'filepath':filepath,'target':d}, ignore_index=True)\n","#                 count+=1\n","#         l.append(count)\n","    "],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:48:47.384325Z","iopub.execute_input":"2022-04-08T13:48:47.385131Z","iopub.status.idle":"2022-04-08T13:48:59.284592Z","shell.execute_reply.started":"2022-04-08T13:48:47.385065Z","shell.execute_reply":"2022-04-08T13:48:59.283617Z"},"trusted":true,"id":"My00TGhiVkK4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# l"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:34:13.577453Z","iopub.execute_input":"2022-04-08T13:34:13.578168Z","iopub.status.idle":"2022-04-08T13:34:13.588108Z","shell.execute_reply.started":"2022-04-08T13:34:13.578114Z","shell.execute_reply":"2022-04-08T13:34:13.58717Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true,"id":"w37VqiRKVkK7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:49:05.818705Z","iopub.execute_input":"2022-04-08T13:49:05.818947Z","iopub.status.idle":"2022-04-08T13:49:05.831704Z","shell.execute_reply.started":"2022-04-08T13:49:05.818923Z","shell.execute_reply":"2022-04-08T13:49:05.830002Z"},"trusted":true,"id":"VddpFascVkK9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf['mel_spect'] = datadf.apply(lambda row:getMelSpectogram(row['filepath']), axis=1)"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:49:51.669227Z","iopub.execute_input":"2022-04-08T13:49:51.66946Z","iopub.status.idle":"2022-04-08T13:54:34.686655Z","shell.execute_reply.started":"2022-04-08T13:49:51.669436Z","shell.execute_reply":"2022-04-08T13:54:34.685434Z"},"trusted":true,"id":"8L6Y9nkJVkK_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def getMelSpectogram(filepath):\n","#     y, sr = librosa.load(filepath)\n","#     return y"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:49:49.662816Z","iopub.execute_input":"2022-04-08T13:49:49.663089Z","iopub.status.idle":"2022-04-08T13:49:49.667633Z","shell.execute_reply.started":"2022-04-08T13:49:49.66306Z","shell.execute_reply":"2022-04-08T13:49:49.666681Z"},"trusted":true,"id":"sPmEyx6zVkLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:38:28.61193Z","iopub.status.idle":"2022-04-08T13:38:28.612301Z","shell.execute_reply.started":"2022-04-08T13:38:28.612099Z","shell.execute_reply":"2022-04-08T13:38:28.612125Z"},"trusted":true,"id":"oDF49nqvVkLD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# traindf=pd.read_csv('../input/birdclef-2022/train_metadata.csv')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:38:28.614221Z","iopub.status.idle":"2022-04-08T13:38:28.614869Z","shell.execute_reply.started":"2022-04-08T13:38:28.614536Z","shell.execute_reply":"2022-04-08T13:38:28.614569Z"},"trusted":true,"id":"ncey1KkrVkLF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# traindf.head()"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:38:28.617027Z","iopub.status.idle":"2022-04-08T13:38:28.617537Z","shell.execute_reply.started":"2022-04-08T13:38:28.617267Z","shell.execute_reply":"2022-04-08T13:38:28.617296Z"},"trusted":true,"id":"krk958e6VkLG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# count "],"metadata":{"trusted":true,"id":"GmeLTChyVkLH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# j"],"metadata":{"trusted":true,"id":"zJYJhd3FVkLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# npcount = np.array(count)"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"8wCpDxUaVkLK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# npcount=npcount[npcount!=0]"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"pj726V7UVkLL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.average(npcount)"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"te1DH5KJVkLM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# np.median(npcount)"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"9XaACkY2VkLN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# datadf"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"RB9MQCOWVkLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sf.read('../input/birdclef-2022/train_audio/bongul/XC516224.ogg')"],"metadata":{"jupyter":{"source_hidden":true},"trusted":true,"id":"Zd1OFIeNVkLP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# y, sr = librosa.load('../input/birdclef-2022/train_audio/afrsil1/XC125458.ogg')\n","# plt.plot(y);\n","# plt.title('Signal');\n","# plt.xlabel('Time (samples)');\n","# plt.ylabel('Amplitude');"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:49:39.939672Z","iopub.execute_input":"2022-04-08T13:49:39.939926Z","iopub.status.idle":"2022-04-08T13:49:41.297418Z","shell.execute_reply.started":"2022-04-08T13:49:39.939902Z","shell.execute_reply":"2022-04-08T13:49:41.296172Z"},"trusted":true,"id":"RrV8DEeCVkLQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# y"],"metadata":{"execution":{"iopub.status.busy":"2022-04-08T13:49:42.128565Z","iopub.execute_input":"2022-04-08T13:49:42.12879Z","iopub.status.idle":"2022-04-08T13:49:42.135155Z","shell.execute_reply.started":"2022-04-08T13:49:42.12876Z","shell.execute_reply":"2022-04-08T13:49:42.134353Z"},"trusted":true,"id":"ygakBuW-VkLR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# n_fft = 2048\n","# ft = np.abs(librosa.stft(y[:n_fft], hop_length = n_fft+1))\n","# plt.plot(ft);\n","# plt.title('Spectrum');\n","# plt.xlabel('Frequency Bin');\n","# plt.ylabel('Amplitude');"],"metadata":{"trusted":true,"id":"8zUWw99TVkLS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# spec = np.abs(librosa.stft(y, hop_length=512))\n","# spec = librosa.amplitude_to_db(spec, ref=np.max)\n","# librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='log');\n","# plt.colorbar(format='%+2.0f dB');\n","# plt.title('Spectrogram');"],"metadata":{"trusted":true,"id":"2ncA_8y6VkLT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\n","# mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n","# librosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');\n","# plt.title('Mel Spectrogram');\n","# plt.colorbar(format='%+2.0f dB');"],"metadata":{"trusted":true,"id":"iH0DmWLJVkLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mel_spect"],"metadata":{"trusted":true,"id":"lnolJ9jNVkLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mel_spect.shape"],"metadata":{"trusted":true,"id":"gU9z6uhvVkLV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# traindf"],"metadata":{"trusted":true,"id":"n4jpPfmiVkLW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## labels , images equivalent (using librosa) ,  reshape images\n"],"metadata":{"id":"F59-EtpPVkLW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# START HERE"],"metadata":{"id":"Ydo3yMThVkLh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75c9y2hLvuQb","executionInfo":{"status":"ok","timestamp":1652321721448,"user_tz":-330,"elapsed":31020,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}},"outputId":"f1183436-6abc-47b2-813e-66832ce2a2b7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/timm/pytorch-image-models-master'\n","!pip install '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/torchlibrosa-0.0.4-py3-none-any.whl'"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:17:54.215313Z","iopub.execute_input":"2022-04-10T11:17:54.215904Z","iopub.status.idle":"2022-04-10T11:17:57.516480Z","shell.execute_reply.started":"2022-04-10T11:17:54.215854Z","shell.execute_reply":"2022-04-10T11:17:57.515531Z"},"trusted":true,"id":"VG4uFL1tVkLj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652321967732,"user_tz":-330,"elapsed":1550,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}},"outputId":"48dde192-247e-4250-f37b-20a425717de3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Invalid requirement: '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/timm/pytorch-image-models-master'\n","Hint: It looks like a path. File '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/timm/pytorch-image-models-master' does not exist.\u001b[0m\n","\u001b[33mWARNING: Requirement '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/torchlibrosa-0.0.4-py3-none-any.whl' looks like a filename, but the file does not exist\u001b[0m\n","Processing ./drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/torchlibrosa-0.0.4-py3-none-any.whl\n","\u001b[31mERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/torchlibrosa-0.0.4-py3-none-any.whl'\n","\u001b[0m\n"]}]},{"cell_type":"code","source":["!pip install geopandas\n","!pip install timm\n","!pip install torchlibrosa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xtuqZ5T8w6Hp","executionInfo":{"status":"ok","timestamp":1652321993940,"user_tz":-330,"elapsed":21539,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}},"outputId":"b4e0eaee-af3e-4d2c-ceb2-d898215bb5c9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting geopandas\n","  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n","\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 42.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 30 kB 45.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40 kB 31.1 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 61 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 163 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 194 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 225 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 256 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 266 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 317 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 327 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 337 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 348 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 358 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 378 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 399 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 409 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 430 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 440 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 450 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 460 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 471 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 491 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 501 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 512 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 522 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 532 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 542 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 552 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 563 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 573 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 593 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 604 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 624 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 634 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 645 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 655 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 665 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 675 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 686 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 696 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 706 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 716 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 727 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 737 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 747 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 757 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 768 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 778 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 788 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 798 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 819 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 829 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 839 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 849 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 860 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 870 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 880 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 890 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 901 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 911 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 921 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 931 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 942 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 952 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 962 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 972 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 983 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 993 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0 MB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0 MB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0 MB 32.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0 MB 32.0 MB/s \n","\u001b[?25hRequirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.1.post1)\n","Collecting pyproj>=2.2.0\n","  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n","\u001b[K     |████████████████████████████████| 6.3 MB 25.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.3.5)\n","Collecting fiona>=1.8\n","  Downloading Fiona-1.8.21-cp37-cp37m-manylinux2014_x86_64.whl (16.7 MB)\n","\u001b[K     |████████████████████████████████| 16.7 MB 397 kB/s \n","\u001b[?25hCollecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Collecting click-plugins>=1.0\n","  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n","Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (21.4.0)\n","Collecting cligj>=0.5\n","  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n","Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (1.15.0)\n","Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (7.1.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (2021.10.8)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas) (57.4.0)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (1.21.6)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas) (2022.1)\n","Installing collected packages: munch, cligj, click-plugins, pyproj, fiona, geopandas\n","Successfully installed click-plugins-1.1.1 cligj-0.7.2 fiona-1.8.21 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1\n","Collecting timm\n","  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n","\u001b[K     |████████████████████████████████| 431 kB 24.3 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.11.0+cu113)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.12.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.2.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2021.10.8)\n","Installing collected packages: timm\n","Successfully installed timm-0.5.4\n","Collecting torchlibrosa\n","  Downloading torchlibrosa-0.0.9-py3-none-any.whl (11 kB)\n","Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from torchlibrosa) (0.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchlibrosa) (1.21.6)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.6.0)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.51.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (2.1.9)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.0.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.4.1)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (1.1.0)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.2.2)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (4.4.2)\n","Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (0.10.3.post1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.6.0->torchlibrosa) (21.3)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.0->torchlibrosa) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.6.0->torchlibrosa) (57.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.6.0->torchlibrosa) (3.0.8)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2.23.0)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.6.0->torchlibrosa) (1.4.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.0->torchlibrosa) (2.10)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa>=0.6.0->torchlibrosa) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.0->torchlibrosa) (3.1.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.6.0->torchlibrosa) (1.15.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.0->torchlibrosa) (2.21)\n","Installing collected packages: torchlibrosa\n","Successfully installed torchlibrosa-0.0.9\n"]}]},{"cell_type":"code","source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import matplotlib.image as mpimg\n","from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n","\n","import plotly.graph_objects as go\n","import plotly.express as px\n","import descartes\n","import geopandas as gpd\n","from shapely.geometry import Point, Polygon\n","import librosa\n","import librosa.display\n","import IPython.display as ipd\n","\n","\n","import sklearn\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","import cv2\n","import audioread\n","import logging\n","\n","import random\n","import time\n","\n","\n","import soundfile as sf\n","import timm\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data as torchdata\n","\n","from contextlib import contextmanager\n","from pathlib import Path\n","from typing import Optional\n","\n","from albumentations.core.transforms_interface import ImageOnlyTransform\n","from torchlibrosa.stft import LogmelFilterBank, Spectrogram\n","from torchlibrosa.augmentation import SpecAugmentation\n","from tqdm import tqdm\n"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:09:01.942124Z","iopub.execute_input":"2022-04-10T11:09:01.942484Z","iopub.status.idle":"2022-04-10T11:09:06.732613Z","shell.execute_reply.started":"2022-04-10T11:09:01.942379Z","shell.execute_reply":"2022-04-10T11:09:06.731400Z"},"trusted":true,"id":"mkeGyzU2VkLk","executionInfo":{"status":"ok","timestamp":1652322002583,"user_tz":-330,"elapsed":8651,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#taxonomy = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/eBird_Taxonomy_v2021.csv')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:36:29.007117Z","iopub.execute_input":"2022-04-10T10:36:29.008014Z","iopub.status.idle":"2022-04-10T10:36:29.101772Z","shell.execute_reply.started":"2022-04-10T10:36:29.007957Z","shell.execute_reply":"2022-04-10T10:36:29.100984Z"},"trusted":true,"id":"g2O7Rcl_VkLa","executionInfo":{"status":"ok","timestamp":1652322201926,"user_tz":-330,"elapsed":323,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Anirudh's directory\n","taxonomy = pd.read_csv('/content/drive/MyDrive/BIRDCLEF-2022/BirdCLEFData/eBird_Taxonomy_v2021.csv')"],"metadata":{"id":"ZMYN3TWxEZCK","executionInfo":{"status":"ok","timestamp":1652322196167,"user_tz":-330,"elapsed":1232,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["taxonomy"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:36:33.497973Z","iopub.execute_input":"2022-04-10T10:36:33.498270Z","iopub.status.idle":"2022-04-10T10:36:33.524430Z","shell.execute_reply.started":"2022-04-10T10:36:33.498237Z","shell.execute_reply":"2022-04-10T10:36:33.523561Z"},"trusted":true,"id":"_HQQTX9VVkLb","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1652322205496,"user_tz":-330,"elapsed":336,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}},"outputId":"e9970be5-54ff-4d08-edc6-9b731265f529"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       TAXON_ORDER CATEGORY SPECIES_CODE         PRIMARY_COM_NAME  \\\n","0                1  species      ostric2           Common Ostrich   \n","1                6  species      ostric3           Somali Ostrich   \n","2                7    slash       y00934    Common/Somali Ostrich   \n","3                8  species      grerhe1             Greater Rhea   \n","4               14  species      lesrhe2              Lesser Rhea   \n","...            ...      ...          ...                      ...   \n","16748        34694  species      slcgro1   Slate-colored Grosbeak   \n","16749        34697  species      bltgro2  Black-throated Grosbeak   \n","16750        34698     spuh      saltat1             saltator sp.   \n","16751        34699     spuh      passer1            passerine sp.   \n","16752        35000     spuh        bird1                 bird sp.   \n","\n","                             SCI_NAME            ORDER1  \\\n","0                    Struthio camelus  Struthioniformes   \n","1              Struthio molybdophanes  Struthioniformes   \n","2      Struthio camelus/molybdophanes  Struthioniformes   \n","3                      Rhea americana        Rheiformes   \n","4                        Rhea pennata        Rheiformes   \n","...                               ...               ...   \n","16748                Saltator grossus     Passeriformes   \n","16749            Saltator fuliginosus     Passeriformes   \n","16750                    Saltator sp.     Passeriformes   \n","16751               Passeriformes sp.     Passeriformes   \n","16752                        Aves sp.               NaN   \n","\n","                                 FAMILY SPECIES_GROUP REPORT_AS  \n","0             Struthionidae (Ostriches)     Ostriches       NaN  \n","1             Struthionidae (Ostriches)           NaN       NaN  \n","2             Struthionidae (Ostriches)           NaN       NaN  \n","3                       Rheidae (Rheas)         Rheas       NaN  \n","4                       Rheidae (Rheas)           NaN       NaN  \n","...                                 ...           ...       ...  \n","16748  Thraupidae (Tanagers and Allies)           NaN       NaN  \n","16749  Thraupidae (Tanagers and Allies)           NaN       NaN  \n","16750  Thraupidae (Tanagers and Allies)           NaN       NaN  \n","16751                               NaN        Others       NaN  \n","16752                               NaN           NaN       NaN  \n","\n","[16753 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-49822309-73a6-4996-a7d2-63a7fd31f51e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TAXON_ORDER</th>\n","      <th>CATEGORY</th>\n","      <th>SPECIES_CODE</th>\n","      <th>PRIMARY_COM_NAME</th>\n","      <th>SCI_NAME</th>\n","      <th>ORDER1</th>\n","      <th>FAMILY</th>\n","      <th>SPECIES_GROUP</th>\n","      <th>REPORT_AS</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>species</td>\n","      <td>ostric2</td>\n","      <td>Common Ostrich</td>\n","      <td>Struthio camelus</td>\n","      <td>Struthioniformes</td>\n","      <td>Struthionidae (Ostriches)</td>\n","      <td>Ostriches</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6</td>\n","      <td>species</td>\n","      <td>ostric3</td>\n","      <td>Somali Ostrich</td>\n","      <td>Struthio molybdophanes</td>\n","      <td>Struthioniformes</td>\n","      <td>Struthionidae (Ostriches)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7</td>\n","      <td>slash</td>\n","      <td>y00934</td>\n","      <td>Common/Somali Ostrich</td>\n","      <td>Struthio camelus/molybdophanes</td>\n","      <td>Struthioniformes</td>\n","      <td>Struthionidae (Ostriches)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8</td>\n","      <td>species</td>\n","      <td>grerhe1</td>\n","      <td>Greater Rhea</td>\n","      <td>Rhea americana</td>\n","      <td>Rheiformes</td>\n","      <td>Rheidae (Rheas)</td>\n","      <td>Rheas</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>14</td>\n","      <td>species</td>\n","      <td>lesrhe2</td>\n","      <td>Lesser Rhea</td>\n","      <td>Rhea pennata</td>\n","      <td>Rheiformes</td>\n","      <td>Rheidae (Rheas)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>16748</th>\n","      <td>34694</td>\n","      <td>species</td>\n","      <td>slcgro1</td>\n","      <td>Slate-colored Grosbeak</td>\n","      <td>Saltator grossus</td>\n","      <td>Passeriformes</td>\n","      <td>Thraupidae (Tanagers and Allies)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16749</th>\n","      <td>34697</td>\n","      <td>species</td>\n","      <td>bltgro2</td>\n","      <td>Black-throated Grosbeak</td>\n","      <td>Saltator fuliginosus</td>\n","      <td>Passeriformes</td>\n","      <td>Thraupidae (Tanagers and Allies)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16750</th>\n","      <td>34698</td>\n","      <td>spuh</td>\n","      <td>saltat1</td>\n","      <td>saltator sp.</td>\n","      <td>Saltator sp.</td>\n","      <td>Passeriformes</td>\n","      <td>Thraupidae (Tanagers and Allies)</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16751</th>\n","      <td>34699</td>\n","      <td>spuh</td>\n","      <td>passer1</td>\n","      <td>passerine sp.</td>\n","      <td>Passeriformes sp.</td>\n","      <td>Passeriformes</td>\n","      <td>NaN</td>\n","      <td>Others</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>16752</th>\n","      <td>35000</td>\n","      <td>spuh</td>\n","      <td>bird1</td>\n","      <td>bird sp.</td>\n","      <td>Aves sp.</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>16753 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49822309-73a6-4996-a7d2-63a7fd31f51e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-49822309-73a6-4996-a7d2-63a7fd31f51e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-49822309-73a6-4996-a7d2-63a7fd31f51e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["meta = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/train_metadata.csv')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:37:07.708749Z","iopub.execute_input":"2022-04-10T10:37:07.709064Z","iopub.status.idle":"2022-04-10T10:37:07.822578Z","shell.execute_reply.started":"2022-04-10T10:37:07.709031Z","shell.execute_reply":"2022-04-10T10:37:07.821932Z"},"trusted":true,"id":"zJeJD5QzVkLc","colab":{"base_uri":"https://localhost:8080/","height":311},"executionInfo":{"status":"error","timestamp":1652322217214,"user_tz":-330,"elapsed":329,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}},"outputId":"addb8e82-462b-49de-f2f8-9a2e8726afbc"},"execution_count":12,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-d1dc31424cc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/train_metadata.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/train_metadata.csv'"]}]},{"cell_type":"code","source":["meta"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:37:10.486616Z","iopub.execute_input":"2022-04-10T10:37:10.486950Z","iopub.status.idle":"2022-04-10T10:37:10.517116Z","shell.execute_reply.started":"2022-04-10T10:37:10.486913Z","shell.execute_reply":"2022-04-10T10:37:10.516189Z"},"trusted":true,"id":"PZ4toU7BVkLc","executionInfo":{"status":"aborted","timestamp":1652322002947,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of train samples\\n')\n","print(meta.shape[0])"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:38:25.295830Z","iopub.execute_input":"2022-04-10T10:38:25.296168Z","iopub.status.idle":"2022-04-10T10:38:25.301844Z","shell.execute_reply.started":"2022-04-10T10:38:25.296132Z","shell.execute_reply":"2022-04-10T10:38:25.300982Z"},"trusted":true,"id":"cvlP0fWHVkLd","executionInfo":{"status":"aborted","timestamp":1652322002947,"user_tz":-330,"elapsed":10,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of primary labels')\n","print(meta['primary_label'].value_counts())"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:39:17.655275Z","iopub.execute_input":"2022-04-10T10:39:17.655794Z","iopub.status.idle":"2022-04-10T10:39:17.671274Z","shell.execute_reply.started":"2022-04-10T10:39:17.655748Z","shell.execute_reply":"2022-04-10T10:39:17.670402Z"},"trusted":true,"id":"vatiu7IZVkLe","executionInfo":{"status":"aborted","timestamp":1652322002948,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(meta.columns)"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:40:11.640314Z","iopub.execute_input":"2022-04-10T10:40:11.640651Z","iopub.status.idle":"2022-04-10T10:40:11.645451Z","shell.execute_reply.started":"2022-04-10T10:40:11.640613Z","shell.execute_reply":"2022-04-10T10:40:11.644788Z"},"trusted":true,"id":"7nL_7GZRVkLf","executionInfo":{"status":"aborted","timestamp":1652322002949,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Labels')\n","print(meta['primary_label'].unique())\n","print(len(meta['primary_label'].unique()))\n","print('NUMBER OF SAMPLES '+str(len(meta['primary_label'])))"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:42:05.970275Z","iopub.execute_input":"2022-04-10T10:42:05.970798Z","iopub.status.idle":"2022-04-10T10:42:05.978110Z","shell.execute_reply.started":"2022-04-10T10:42:05.970734Z","shell.execute_reply":"2022-04-10T10:42:05.977022Z"},"trusted":true,"id":"-fHxxyDxVkLf","executionInfo":{"status":"aborted","timestamp":1652322002949,"user_tz":-330,"elapsed":11,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of classes')\n","# print(type(meta['primary_label'].unique()))\n","print(meta['primary_label'].unique().shape)"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:45:48.783442Z","iopub.execute_input":"2022-04-10T10:45:48.784010Z","iopub.status.idle":"2022-04-10T10:45:48.792405Z","shell.execute_reply.started":"2022-04-10T10:45:48.783973Z","shell.execute_reply":"2022-04-10T10:45:48.791534Z"},"trusted":true,"id":"QbqqjYU_VkLg","executionInfo":{"status":"aborted","timestamp":1652322002950,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["meta"],"metadata":{"id":"PjSANz64efEC","executionInfo":{"status":"aborted","timestamp":1652322002950,"user_tz":-330,"elapsed":12,"user":{"displayName":"Anirudh A","userId":"00619644380298687637"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some more EDA"],"metadata":{"id":"e9E1bnq-ENHJ"}},{"cell_type":"code","source":[""],"metadata":{"id":"cGefOexDEM0J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Trying to import torch models for training"],"metadata":{"id":"xdGU7htqVkLg"}},{"cell_type":"code","source":["# BASE_DIR = '/content/drive/MyDrive/Colab Notebooks/birdclef-2022.zip'"],"metadata":{"id":"jczXa9KMxUNU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !unzip '/content/drive/MyDrive/Colab Notebooks/birdclef-2022.zip'"],"metadata":{"id":"GyVuoRcexW1j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import zipfile\n","\n","# with zipfile.ZipFile('/content/drive/MyDrive/Colab Notebooks/birdclef-2022.zip', \"r\") as z:\n","#   z.extractall(\"/content/drive/MyDrive/Colab Notebooks/BirdCLEFData\")\n"],"metadata":{"id":"du6KX2FNJBR9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed: int = 108):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","    \n","    \n","def get_logger(out_file=None):\n","    logger = logging.getLogger()\n","    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n","    logger.handlers = []\n","    logger.setLevel(logging.INFO)\n","\n","    handler = logging.StreamHandler()\n","    handler.setFormatter(formatter)\n","    handler.setLevel(logging.INFO)\n","    logger.addHandler(handler)\n","\n","    if out_file is not None:\n","        fh = logging.FileHandler(out_file)\n","        fh.setFormatter(formatter)\n","        fh.setLevel(logging.INFO)\n","        logger.addHandler(fh)\n","    logger.info(\"logger set up\")\n","    return logger\n","    \n","    \n","@contextmanager\n","def timer(name: str, logger: Optional[logging.Logger] = None):\n","    t0 = time.time()\n","    msg = f\"[{name}] start\"\n","    if logger is None:\n","        print(msg)\n","    else:\n","        logger.info(msg)\n","    yield\n","\n","    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n","    if logger is None:\n","        print(msg)\n","    else:\n","        logger.info(msg)"],"metadata":{"id":"3vFTFHG0MH4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger = get_logger(\"main.log\")\n","set_seed(108)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGbOzi2oMJDi","executionInfo":{"status":"ok","timestamp":1650111090625,"user_tz":-330,"elapsed":53,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"outputId":"20c445d6-61cb-443c-cf7d-53944c376470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-04-16 12:11:29,630 - INFO - logger set up\n"]}]},{"cell_type":"code","source":["import json\n"," \n","# Opening JSON file\n","f = open('/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/scored_birds.json')\n","\n","# returns JSON object as\n","# a dictionary\n","data = json.load(f)\n"," \n","# Iterating through the json\n","# list\n","print(len(data))\n","for i in data:\n","    print(i)"],"metadata":{"id":"odkfUa8vYS1A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650111360254,"user_tz":-330,"elapsed":1162,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"outputId":"2b158069-a04a-4893-e8c0-ca3ee8268262"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["21\n","akiapo\n","aniani\n","apapan\n","barpet\n","crehon\n","elepai\n","ercfra\n","hawama\n","hawcre\n","hawgoo\n","hawhaw\n","hawpet1\n","houfin\n","iiwi\n","jabwar\n","maupar\n","omao\n","puaioh\n","skylar\n","warwhe1\n","yefcan\n"]}]},{"cell_type":"code","source":["class CFG:\n","\n","    seed = 108\n","    epochs = 60\n","    train = True\n","    folds = [0]\n","    img_size = 224\n","    main_metric = \"epoch_f1_at_05\"\n","    minimize_metric = False\n","\n","\n","    train_datadir = Path(\"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/train_audio\")\n","    train_csv = \"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/train_metadata.csv\"\n","\n","    \n","    transforms = {\n","        \"train\": [{\"name\": \"Normalize\"}],\n","        \"valid\": [{\"name\": \"Normalize\"}],\n","        \"test\": [{\"name\": \"Normalize\"}]\n","    }\n","    period = 20\n","    n_mels = 128\n","    fmin = 20\n","    fmax = 16000\n","    n_fft = 2048\n","    hop_length = 512\n","    sample_rate = 32000\n","    melspectrogram_parameters = {\n","        \"n_mels\": 224,\n","        \"fmin\": 20,\n","        \"fmax\": 16000\n","    }\n","\n","    target_columns = meta['primary_label'].unique()\n","\n","\n","    loader_params = {\n","        \"train\": {\n","            \"batch_size\": 64,\n","            \"num_workers\": 20,\n","            \"shuffle\": True\n","        },\n","        \"valid\": {\n","            \"batch_size\": 64,\n","            \"num_workers\": 20,\n","            \"shuffle\": False\n","        },\n","        \"test\": {\n","            \"batch_size\": 64,\n","            \"num_workers\": 20,\n","            \"shuffle\": False\n","        }\n","    }\n","\n","    \n","    split = \"StratifiedKFold\"\n","    split_params = {\n","        \"n_splits\": 5,\n","        \"shuffle\": True,\n","        \"random_state\": 108\n","    }\n","\n","\n","    \n","    base_model_name = \"tf_efficientnet_b0_ns\"\n","    pooling = \"max\"\n","    pretrained = True\n","    num_classes = 152\n","    in_channels = 1\n","\n","\n","    loss_name = \"BCEFocal2WayLoss\"\n","    loss_params: dict = {}\n","\n","        \n","    optimizer_name = \"Adam\"\n","    base_optimizer = \"Adam\"\n","    optimizer_params = {\n","        \"lr\": 0.0015\n","    }\n","\n","    base_optimizer = \"Adam\"\n","\n","    \n","    scheduler_name = \"CosineAnnealingLR\"\n","    scheduler_params = {\n","        \"T_max\": 10\n","    }"],"metadata":{"execution":{"iopub.status.busy":"2022-04-10T10:56:56.730502Z","iopub.execute_input":"2022-04-10T10:56:56.731753Z","iopub.status.idle":"2022-04-10T10:56:56.777767Z","shell.execute_reply.started":"2022-04-10T10:56:56.731683Z","shell.execute_reply":"2022-04-10T10:56:56.776394Z"},"trusted":true,"id":"stpLLNSVVkLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TARGET_SR = 32000\n","DATADIR = Path(\"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/test_soundscapes\")"],"metadata":{"id":"sA2Ix0RnVkLn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_audios = list(DATADIR.glob(\"*.ogg\"))\n","all_audio_ids = [\"_\".join(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n","submission_df = pd.DataFrame({\n","    \"row_id\": all_audio_ids\n","})\n"],"metadata":{"id":"pAjkmkjqK-DO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submission_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81},"id":"MLWa2BSyLEyy","executionInfo":{"status":"ok","timestamp":1650112644872,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"outputId":"9de9265e-6f44-4804-d82a-ca99fb88fc0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     row_id\n","0  soundscape_453028782.ogg"],"text/html":["\n","  <div id=\"df-8e9a21b5-5866-442e-b8c0-afdd19277d79\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>soundscape_453028782.ogg</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e9a21b5-5866-442e-b8c0-afdd19277d79')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8e9a21b5-5866-442e-b8c0-afdd19277d79 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8e9a21b5-5866-442e-b8c0-afdd19277d79');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["def init_layer(layer):\n","    nn.init.xavier_uniform_(layer.weight)\n","\n","    if hasattr(layer, \"bias\"):\n","        if layer.bias is not None:\n","            layer.bias.data.fill_(0.)\n","\n","\n","def init_bn(bn):\n","    bn.bias.data.fill_(0.)\n","    bn.weight.data.fill_(1.0)\n","\n","\n","def init_weights(model):\n","    classname = model.__class__.__name__\n","    if classname.find(\"Conv2d\") != -1:\n","        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"BatchNorm\") != -1:\n","        model.weight.data.normal_(1.0, 0.02)\n","        model.bias.data.fill_(0)\n","    elif classname.find(\"GRU\") != -1:\n","        for weight in model.parameters():\n","            if len(weight.size()) > 1:\n","                nn.init.orghogonal_(weight.data)\n","    elif classname.find(\"Linear\") != -1:\n","        model.weight.data.normal_(0, 0.01)\n","        model.bias.data.zero_()\n","\n","\n","def do_mixup(x: torch.Tensor, mixup_lambda: torch.Tensor):\n","\n","    out = (x[0::2].transpose(0, -1) * mixup_lambda[0::2] +\n","           x[1::2].transpose(0, -1) * mixup_lambda[1::2]).transpose(0, -1)\n","    return out\n","\n","\n","class Mixup(object):\n","    def __init__(self, mixup_alpha, random_seed=108):\n","\n","        self.mixup_alpha = mixup_alpha\n","        self.random_state = np.random.RandomState(random_seed)\n","\n","    def get_lambda(self, batch_size):\n","        mixup_lambdas = []\n","        for n in range(0, batch_size, 2):\n","            lam = self.random_state.beta(\n","                self.mixup_alpha, self.mixup_alpha, 1)[0]\n","            mixup_lambdas.append(lam)\n","            mixup_lambdas.append(1. - lam)\n","\n","        return torch.from_numpy(np.array(mixup_lambdas, dtype=np.float32))\n","\n","\n","def interpolate(x: torch.Tensor, ratio: int):\n","\n","    (batch_size, time_steps, classes_num) = x.shape\n","    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n","    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n","    return upsampled\n","\n","\n","def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n","\n","    output = F.interpolate(\n","        framewise_output.unsqueeze(1),\n","        size=(frames_num, framewise_output.size(2)),\n","        align_corners=True,\n","        mode=\"bilinear\").squeeze(1)\n","\n","    return output\n","\n","\n","def gem(x: torch.Tensor, p=3, eps=1e-6):\n","    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1. / p)\n","\n","\n","class GeM(nn.Module):\n","    def __init__(self, p=3, eps=1e-6):\n","        super().__init__()\n","        self.p = nn.Parameter(torch.ones(1) * p)\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        return gem(x, p=self.p, eps=self.eps)\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + f\"(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n","\n","\n","class AttBlockV2(nn.Module):\n","    def __init__(self,\n","                 in_features: int,\n","                 out_features: int,\n","                 activation=\"linear\"):\n","        super().__init__()\n","\n","        self.activation = activation\n","        self.att = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","        self.cla = nn.Conv1d(\n","            in_channels=in_features,\n","            out_channels=out_features,\n","            kernel_size=1,\n","            stride=1,\n","            padding=0,\n","            bias=True)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        init_layer(self.att)\n","        init_layer(self.cla)\n","\n","    def forward(self, x):\n","        # x: (n_samples, n_in, n_time)\n","        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n","        cla = self.nonlinear_transform(self.cla(x))\n","        x = torch.sum(norm_att * cla, dim=2)\n","        return x, norm_att, cla\n","\n","    def nonlinear_transform(self, x):\n","        if self.activation == 'linear':\n","            return x\n","        elif self.activation == 'sigmoid':\n","            return torch.sigmoid(x)\n","\n","droprate=0.2 #0.5\n","\n","class TimmSED(nn.Module):\n","    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1): \n","        super().__init__()\n","        # Spectrogram extractor\n","        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n","                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n","                                                 freeze_parameters=True)\n","\n","        # Logmel feature extractor\n","        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n","                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n","                                                 freeze_parameters=True)\n","\n","        # Spec augmenter\n","        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n","                                               freq_drop_width=8, freq_stripes_num=2)\n","\n","        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n","\n","        base_model = timm.create_model(\n","            base_model_name, pretrained=pretrained, in_chans=in_channels)\n","        layers = list(base_model.children())[:-2]\n","        self.encoder = nn.Sequential(*layers)\n","\n","        if hasattr(base_model, \"fc\"):\n","            in_features = base_model.fc.in_features\n","        else:\n","            in_features = base_model.classifier.in_features\n","        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n","        self.att_block = AttBlockV2(\n","            in_features, num_classes, activation=\"sigmoid\")\n","\n","        self.init_weight()\n","\n","    def init_weight(self):\n","        init_layer(self.fc1)\n","        init_bn(self.bn0)\n","\n","    def forward(self, input):\n","        # (batch_size, 1, time_steps, freq_bins)\n","        x = self.spectrogram_extractor(input)\n","        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n","\n","        frames_num = x.shape[2]\n","\n","        x = x.transpose(1, 3)\n","        x = self.bn0(x)\n","        x = x.transpose(1, 3)\n","\n","        if self.training:\n","            x = self.spec_augmenter(x)\n","\n","        x = x.transpose(2, 3)\n","        # (batch_size, channels, freq, frames)\n","        x = self.encoder(x)\n","\n","        # (batch_size, channels, frames)\n","        x = torch.mean(x, dim=2)\n","\n","        # channel smoothing\n","        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n","        x = x1 + x2\n","\n","        x = F.dropout(x, p=droprate, training=self.training)\n","        x = x.transpose(1, 2)\n","        x = F.relu_(self.fc1(x))\n","        x = x.transpose(1, 2)\n","        x = F.dropout(x, p=droprate, training=self.training)\n","        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n","        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n","        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n","        segmentwise_output = segmentwise_output.transpose(1, 2)\n","\n","        interpolate_ratio = frames_num // segmentwise_output.size(1)\n","\n","        # Get framewise output\n","        framewise_output = interpolate(segmentwise_output,\n","                                       interpolate_ratio)\n","        framewise_output = pad_framewise_output(framewise_output, frames_num)\n","\n","        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n","        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n","\n","        output_dict = {\n","            \"framewise_output\": framewise_output,\n","            \"segmentwise_output\": segmentwise_output,\n","            \"logit\": logit,\n","            \"framewise_logit\": framewise_logit,\n","            \"clipwise_output\": clipwise_output\n","        }\n","\n","        return output_dict"],"metadata":{"id":"L61P4a_XLHyG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TestDataset(torchdata.Dataset):\n","    def __init__(self, df: pd.DataFrame, clip: np.ndarray,\n","                 waveform_transforms=None):\n","        self.df = df\n","        self.clip = clip\n","        self.waveform_transforms=waveform_transforms\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx: int):\n","        SR = 32000\n","        sample = self.df.loc[idx, :]\n","        row_id = sample.row_id\n","\n","        end_seconds = int(sample.seconds)\n","        start_seconds = int(end_seconds - 5)\n","\n","        start_index = SR * start_seconds\n","        end_index = SR * end_seconds\n","\n","        y = self.clip[start_index:end_index].astype(np.float32)\n","\n","        y = np.nan_to_num(y)\n","\n","        if self.waveform_transforms:\n","            y = self.waveform_transforms(y)\n","\n","        y = np.nan_to_num(y)\n","\n","        return y, row_id"],"metadata":{"id":"CsG1Ax4ULeWI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_transforms(phase: str):\n","    transforms = CFG.transforms\n","    if transforms is None:\n","        return None\n","    else:\n","        if transforms[phase] is None:\n","            return None\n","        trns_list = []\n","        for trns_conf in transforms[phase]:\n","            trns_name = trns_conf[\"name\"]\n","            trns_params = {} if trns_conf.get(\"params\") is None else \\\n","                trns_conf[\"params\"]\n","            if globals().get(trns_name) is not None:\n","                trns_cls = globals()[trns_name]\n","                trns_list.append(trns_cls(**trns_params))\n","\n","        if len(trns_list) > 0:\n","            return Compose(trns_list)\n","        else:\n","            return None\n","\n","\n","def get_waveform_transforms(config: dict, phase: str):\n","    return get_transforms(config, phase)\n","\n","\n","def get_spectrogram_transforms(config: dict, phase: str):\n","    transforms = config.get('spectrogram_transforms')\n","    if transforms is None:\n","        return None\n","    else:\n","        if transforms[phase] is None:\n","            return None\n","        trns_list = []\n","        for trns_conf in transforms[phase]:\n","            trns_name = trns_conf[\"name\"]\n","            trns_params = {} if trns_conf.get(\"params\") is None else \\\n","                trns_conf[\"params\"]\n","            if hasattr(A, trns_name):\n","                trns_cls = A.__getattribute__(trns_name)\n","                trns_list.append(trns_cls(**trns_params))\n","            else:\n","                trns_cls = globals().get(trns_name)\n","                if trns_cls is not None:\n","                    trns_list.append(trns_cls(**trns_params))\n","\n","        if len(trns_list) > 0:\n","            return A.Compose(trns_list, p=1.0)\n","        else:\n","            return None\n","\n","\n","class Normalize:\n","    def __call__(self, y: np.ndarray):\n","        max_vol = np.abs(y).max()\n","        y_vol = y * 1 / max_vol\n","        return np.asfortranarray(y_vol)\n","\n","\n","class NewNormalize:\n","    def __call__(self, y: np.ndarray):\n","        y_mm = y - y.mean()\n","        return y_mm / y_mm.abs().max()\n","\n","\n","class Compose:\n","    def __init__(self, transforms: list):\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray):\n","        for trns in self.transforms:\n","            y = trns(y)\n","        return y\n","\n","\n","class AudioTransform:\n","    def __init__(self, always_apply=False, p=0.5):\n","        self.always_apply = always_apply\n","        self.p = p\n","\n","    def __call__(self, y: np.ndarray):\n","        if self.always_apply:\n","            return self.apply(y)\n","        else:\n","            if np.random.rand() < self.p:\n","                return self.apply(y)\n","            else:\n","                return y\n","\n","    def apply(self, y: np.ndarray):\n","        raise NotImplementedError\n","\n","\n","class NoiseInjection(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_noise_level=0.5, sr=32000):\n","        super().__init__(always_apply, p)\n","\n","        self.noise_level = (0.0, max_noise_level)\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        noise_level = np.random.uniform(*self.noise_level)\n","        noise = np.random.randn(len(y))\n","        augmented = (y + noise * noise_level).astype(y.dtype)\n","        return augmented\n","\n","\n","class GaussianNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = np.random.uniform(self.min_snr, self.max_snr)\n","        a_signal = np.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        white_noise = np.random.randn(len(y))\n","        a_white = np.sqrt(white_noise ** 2).max()\n","        augmented = (y + white_noise * 1 / a_white * a_noise).astype(y.dtype)\n","        return augmented\n","\n","\n","class PinkNoise(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, min_snr=5, max_snr=20, sr=32000):\n","        super().__init__(always_apply, p)\n","\n","        self.min_snr = min_snr\n","        self.max_snr = max_snr\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        snr = np.random.uniform(self.min_snr, self.max_snr)\n","        a_signal = np.sqrt(y ** 2).max()\n","        a_noise = a_signal / (10 ** (snr / 20))\n","\n","        pink_noise = cn.powerlaw_psd_gaussian(1, len(y))\n","        a_pink = np.sqrt(pink_noise ** 2).max()\n","        augmented = (y + pink_noise * 1 / a_pink * a_noise).astype(y.dtype)\n","        return augmented\n","\n","\n","class PitchShift(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_range=5, sr=32000):\n","        super().__init__(always_apply, p)\n","        self.max_range = max_range\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        n_steps = np.random.randint(-self.max_range, self.max_range)\n","        augmented = librosa.effects.pitch_shift(y, self.sr, n_steps)\n","        return augmented\n","\n","\n","class TimeStretch(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, max_rate=1, sr=32000):\n","        super().__init__(always_apply, p)\n","        self.max_rate = max_rate\n","        self.sr = sr\n","\n","    def apply(self, y: np.ndarray, **params):\n","        rate = np.random.uniform(0, self.max_rate)\n","        augmented = librosa.effects.time_stretch(y, rate)\n","        return augmented\n","\n","\n","def _db2float(db: float, amplitude=True):\n","    if amplitude:\n","        return 10**(db / 20)\n","    else:\n","        return 10 ** (db / 10)\n","\n","\n","def volume_down(y: np.ndarray, db: float):\n","\n","    applied = y * _db2float(-db)\n","    return applied\n","\n","\n","def volume_up(y: np.ndarray, db: float):\n","\n","    applied = y * _db2float(db)\n","    return applied\n","\n","\n","class RandomVolume(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, limit=10):\n","        super().__init__(always_apply, p)\n","        self.limit = limit\n","\n","    def apply(self, y: np.ndarray, **params):\n","        db = np.random.uniform(-self.limit, self.limit)\n","        if db >= 0:\n","            return volume_up(y, db)\n","        else:\n","            return volume_down(y, db)\n","\n","\n","class OneOf:\n","    def __init__(self, transforms: list):\n","        self.transforms = transforms\n","\n","    def __call__(self, y: np.ndarray):\n","        n_trns = len(self.transforms)\n","        trns_idx = np.random.choice(n_trns)\n","        trns = self.transforms[trns_idx]\n","        y = trns(y)\n","        return y\n","\n","\n","class CosineVolume(AudioTransform):\n","    def __init__(self, always_apply=False, p=0.5, limit=10):\n","        super().__init__(always_apply, p)\n","        self.limit = limit\n","\n","    def apply(self, y: np.ndarray, **params):\n","        db = np.random.uniform(-self.limit, self.limit)\n","        cosine = np.cos(np.arange(len(y)) / len(y) * np.pi * 2)\n","        dbs = _db2float(cosine * db)\n","        return y * dbs\n","\n","\n","def drop_stripes(image: np.ndarray, dim: int, drop_width: int, stripes_num: int):\n","    total_width = image.shape[dim]\n","    lowest_value = image.min()\n","    for _ in range(stripes_num):\n","        distance = np.random.randint(low=0, high=drop_width, size=(1,))[0]\n","        begin = np.random.randint(\n","            low=0, high=total_width - distance, size=(1,))[0]\n","\n","        if dim == 0:\n","            image[begin:begin + distance] = lowest_value\n","        elif dim == 1:\n","            image[:, begin + distance] = lowest_value\n","        elif dim == 2:\n","            image[:, :, begin + distance] = lowest_value\n","    return image\n","\n","\n","class TimeFreqMasking(ImageOnlyTransform):\n","    def __init__(self,\n","                 time_drop_width: int,\n","                 time_stripes_num: int,\n","                 freq_drop_width: int,\n","                 freq_stripes_num: int,\n","                 always_apply=False,\n","                 p=0.5):\n","        super().__init__(always_apply, p)\n","        self.time_drop_width = time_drop_width\n","        self.time_stripes_num = time_stripes_num\n","        self.freq_drop_width = freq_drop_width\n","        self.freq_stripes_num = freq_stripes_num\n","\n","    def apply(self, img, **params):\n","        img_ = img.copy()\n","        if img.ndim == 2:\n","            img_ = drop_stripes(\n","                img_, dim=0, drop_width=self.freq_drop_width, stripes_num=self.freq_stripes_num)\n","            img_ = drop_stripes(\n","                img_, dim=1, drop_width=self.time_drop_width, stripes_num=self.time_stripes_num)\n","        return img_"],"metadata":{"id":"8LW9Y694Lhc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import OrderedDict"],"metadata":{"id":"36nTsvA9kaQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_model_for_inference(model, path: Path):\n","    if not torch.cuda.is_available():\n","        ckpt = torch.load(path, map_location=\"cpu\")\n","    else:\n","        ckpt = torch.load(path)\n","    \n","      # original saved file with DataParallel\n","      # state_dict = torch.load(path)\n","      # # create new OrderedDict that does not contain `module.`\n","      # new_state_dict = OrderedDict()\n","      # for k, v in state_dict.items():\n","      #     name = k[7:] # remove `module.`\n","      #     new_state_dict[name] = v\n","        \n","    # checkpoint = torch.load(path)['model']#['model_state_dict']\n","    # for key in list(checkpoint.keys()):\n","    #     if 'model.' in key:\n","    #         checkpoint[key.replace('model.', '')] = checkpoint[key]\n","    #         del checkpoint[key]\n","    # model.load_state_dict(checkpoint)\n","\n","    # # load params\n","    # model = nn.DataParallel(model)\n","    model.load_state_dict(ckpt['model_state_dict'])\n","\n","    # model.load_state_dict(ckpt[\"model\"]) # original : ckpt['model_state_dict'] # try strict=False(DOESNT WORK)\n","    model.eval()\n","    return model"],"metadata":{"id":"qJxiqhdrLngj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction_for_clip(test_df: pd.DataFrame, \n","                        clip: np.ndarray, \n","                        model, \n","                        threshold=0.5):\n","\n","    dataset = TestDataset(df=test_df, \n","                          clip=clip,\n","                          waveform_transforms=get_transforms(phase=\"test\"))\n","    loader = torchdata.DataLoader(dataset, batch_size=1, shuffle=False)\n","    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # commented\n","    device = \"cpu\" # added\n","    model.eval()\n","    prediction_dict = {}\n","    # print(loader) \n","  \n","    for image, row_id in tqdm(loader):\n","  \n","      row_id = row_id[0]\n","      image = image.to(device)\n","\n","      with torch.no_grad():\n","          prediction = model(image)\n","          proba = prediction[\"clipwise_output\"].detach().cpu().numpy().reshape(-1)\n","\n","      events = proba >= threshold\n","      labels = np.argwhere(events).reshape(-1).tolist()\n","\n","      if len(labels) == 0:\n","          prediction_dict[row_id] = \"nocall\"\n","      else:\n","          labels_str_list = list(map(lambda x: CFG.target_columns[x], labels))\n","          label_string = \" \".join(labels_str_list)\n","          prediction_dict[row_id] = label_string\n","    return prediction_dict"],"metadata":{"id":"Nrf8xbQCLpY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction(test_audios,\n","               weights_path: Path,\n","               threshold=0.6):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = TimmSED(base_model_name=CFG.base_model_name,\n","                    pretrained=False, \n","                    num_classes=CFG.num_classes,\n","                    in_channels=CFG.in_channels)\n","    \n","    # model = nn.DataParallel(model) # ZERO SIZE-ERROR # ADDED \n","    model = prepare_model_for_inference(model, weights_path).to(device)\n","\n","    warnings.filterwarnings(\"ignore\")\n","    prediction_dfs = []\n","    for audio_path in test_audios:\n","        with timer(f\"Loading {str(audio_path)}\", logger):\n","            clip, _ = sf.read(audio_path)\n","            \n","        seconds = []\n","        row_ids = []\n","        for second in range(5, 605, 5):\n","            row_id = \"_\".join(audio_path.name.split(\"_\")[:2]) + f\"_{second}\"\n","            seconds.append(second)\n","            row_ids.append(row_id)\n","            \n","        test_df = pd.DataFrame({\n","            \"row_id\": row_ids,\n","            \"seconds\": seconds\n","        })\n","        # print(model)\n","     \n","        with timer(f\"Prediction on {audio_path}\", logger):\n","            prediction_dict = prediction_for_clip(test_df,\n","                                                  clip=clip,\n","                                                  model=model,\n","                                                  threshold=threshold)\n","        row_id = list(prediction_dict.keys())\n","        birds = list(prediction_dict.values())\n","        prediction_df = pd.DataFrame({\n","            \"row_id\": row_id,\n","            \"birds\": birds\n","        })\n","        prediction_dfs.append(prediction_df)\n","    \n","    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n","    return prediction_df\n","  "],"metadata":{"id":"T7fFfvxNLq-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://api.ngc.nvidia.com/v2/models/nvidia/efficientnet_b0_pyt_amp/versions/20.12.0/files/nvidia_efficientnet-b0_210412.pth"],"metadata":{"id":"WfrY5T3RciDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["th=1/4\n","# weights_path = Path(\"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/best.pth\") \n","# weights_path = Path(\"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/birdclef2022-best_accuracy_model.pt\")\n","weights_path=Path('https://api.ngc.nvidia.com/v2/models/nvidia/efficientnet_b0_pyt_amp/versions/20.12.0/files/nvidia_efficientnet-b0_210412.pth')\n","\n","submission = prediction(test_audios=all_audios,\n","                        weights_path=weights_path,\n","                        threshold=th)\n","# submission.to_csv(\"submission.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":486},"id":"oYqDa_WfLt1e","executionInfo":{"status":"error","timestamp":1650113976942,"user_tz":-330,"elapsed":4459,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"outputId":"e1f22fb4-55bc-4c6c-cde1-21f48532b12d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-04-16 12:59:33,998 - INFO - Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_b0_ns-c0e6a31c.pth)\n","2022-04-16 12:59:34,023 - INFO - Converted input conv conv_stem pretrained weights from 3 to 1 channel(s)\n","2022-04-16 12:59:34,088 - INFO - [Loading /content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/test_soundscapes/soundscape_453028782.ogg] start\n","2022-04-16 12:59:34,161 - INFO - [Loading /content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/test_soundscapes/soundscape_453028782.ogg] done in 0.07 s\n","2022-04-16 12:59:34,167 - INFO - [Prediction on /content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/BirdCLEFData/test_soundscapes/soundscape_453028782.ogg] start\n"," 10%|█         | 12/120 [00:01<00:15,  7.04it/s]\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-40b4a38fbb1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m submission = prediction(test_audios=all_audios,\n\u001b[1;32m      7\u001b[0m                         \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         threshold=th)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# submission.to_csv(\"submission.csv\", index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-82-40fdab663e57>\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(test_audios, weights_path, threshold)\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                   \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                                                   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                                                   threshold=threshold)\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mrow_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mbirds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-89-d0c44ef85487>\u001b[0m in \u001b[0;36mprediction_for_clip\u001b[0;34m(test_df, clip, model, threshold)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# print(loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mrow_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-62-2f4f988e4230>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveform_transforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaveform_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-03569f3a5118>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrns\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-03569f3a5118>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mmax_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0my_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_vol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masfortranarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_vol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     38\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     39\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n","\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"]}]},{"cell_type":"code","source":["ckpt = torch.load(weights_path)"],"metadata":{"id":"pd9VwUr7LvfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ckpt.keys()"],"metadata":{"id":"cYhg02aam3pg","executionInfo":{"status":"ok","timestamp":1650112307358,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"51f9ec0d-0f17-48ea-b14a-4e6055828bee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['epoch_metrics', 'valid_metrics', 'stage', 'epoch', 'loader_key', 'loader_batch_step', 'global_epoch', 'checkpoint_data', 'main_metric', 'minimize_metric', 'valid_loader', 'model_state_dict'])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["ckpt['model_state_dict']"],"metadata":{"id":"MdeazCNGhwWp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ckpt"],"metadata":{"id":"IdkU4IJ6mvuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre22=torch.load(Path(\"/content/drive/MyDrive/Colab Notebooks/BIRDCLEF-2022/birdclef2022-best_accuracy_model.pt\"))\n"],"metadata":{"id":"3T74JXaDh7u5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre22.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JE1oZrX-iCcu","executionInfo":{"status":"ok","timestamp":1650098456538,"user_tz":-330,"elapsed":4,"user":{"displayName":"Aarthi Sureshkumar","userId":"06124507808119119778"}},"outputId":"deb14eba-224b-4f00-fe5e-f66e68adc2c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['model', 'optim', 'epoch'])"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["pre22['model']"],"metadata":{"id":"-1DZNeUhiEKr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"afwQai6fiFWR"},"execution_count":null,"outputs":[]}]}